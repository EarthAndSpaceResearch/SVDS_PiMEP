{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96bed78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import numpy.ma as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5621cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance_triple_point_collocation(data1, data2, data3, flag):\n",
    "# Basic Triple Point Collocation Analysis for any combination of datasets\n",
    "# Input datasets must be 2D with dimensions 1xN, Mx1, or MXN \n",
    "# All datasets must have uniform dimensions \n",
    "# Flag: 1 = exclude large dataset differences abs(>5PSU) from analysis, 0=include all dataset differences regardless of size\n",
    "\n",
    "# J. Anderson (janderson@esr.org) based on Stoffelen 1998 & Gruber et al 2016 Covariance Notation \n",
    "    \n",
    "# Error check input data for uniform dimensions and valid flag value\n",
    "# Python automaticaly checks that the correct numbe of imputs were given\n",
    "    num = ((data1.shape == data2.shape)+(data1.shape == data3.shape)+(data2.shape == data3.shape))\n",
    "    \n",
    "    if num != 3:\n",
    "        raise Exception('Input datasets must have uniform dimensions')\n",
    "\n",
    "    if np.isin(flag,[0,1]) == False:\n",
    "        raise Exception('Flag input must be 1 or 0')\n",
    "        \n",
    "    # Prepare data for triple point collocation\n",
    "    # If flag = 1, remove data where absolute value of differences > 5 PSU\n",
    "    if flag == 1:\n",
    "        \n",
    "        #'Data1 - Data3'\n",
    "        ds_d1_d3 = data1-data3; # Calculate the difference between Data1 & Data3\n",
    "        tempLarge = np.where(np.absolute(ds_d1_d3)>5)\n",
    "        data1[tempLarge]='NaN'\n",
    "        data3[tempLarge]='NaN'\n",
    "        del tempLarge, ds_d1_d3\n",
    "        \n",
    "        #'Data2 - Data3'\n",
    "        ds_d2_d3 = data2-data3; # Calculate the difference between Data1 & Data3\n",
    "        tempLarge = np.where(np.absolute(ds_d2_d3)>5)\n",
    "        data2[tempLarge]='NaN'\n",
    "        data3[tempLarge]='NaN'\n",
    "        del tempLarge, ds_d2_d3\n",
    "\n",
    "        #'Data1 - Data2'\n",
    "        ds_d1_d2 = data1-data2; # Calculate the difference between Data1 & Data3\n",
    "        tempLarge = np.where(np.absolute(ds_d1_d2)>5)\n",
    "        data1[tempLarge]='NaN'\n",
    "        data2[tempLarge]='NaN'\n",
    "        del tempLarge, ds_d1_d2\n",
    "    \n",
    "    # Triple point collocation cannot be calculated if one dataset has a NaN. \n",
    "    # Make location of NaNs uniform for all datasets. \n",
    "    data2[np.argwhere(np.isnan(data1))]='NaN'\n",
    "    data3[np.argwhere(np.isnan(data1))]='NaN'\n",
    "\n",
    "    data1[np.argwhere(np.isnan(data2))]='NaN'\n",
    "    data3[np.argwhere(np.isnan(data2))]='NaN'\n",
    "\n",
    "    data1[np.argwhere(np.isnan(data3))]='NaN'\n",
    "    data2[np.argwhere(np.isnan(data3))]='NaN'\n",
    "    \n",
    "    # Start triple point collocation\n",
    "    # Calculate variance of each dataset\n",
    "    var_d1 = np.nanvar(data1,ddof=1) # Variance computed on flattened variance\n",
    "    var_d2 = np.nanvar(data2,ddof=1)\n",
    "    var_d3 = np.nanvar(data3,ddof=1)\n",
    "\n",
    "    # Calculate the covariance of Data1 and Data3\n",
    "    covar_d1_d3 = np.diagonal(ma.cov(ma.array(data1, mask=np.isnan(data1)), ma.array(data3, mask = np.isnan(data3)),ddof=1),offset=1) # covariance of data1 and data3 is off diagonal element, masked to ignore nans\n",
    "\n",
    "    # Calculate the covariance of Data2 and Data3\n",
    "    covar_d2_d3 = np.diagonal(ma.cov(ma.array(data2, mask=np.isnan(data2)), ma.array(data3, mask = np.isnan(data3)),ddof=1),offset=1) # covariance of data2 and data3 is off diagonal element, masked to ignore nans\n",
    "\n",
    "    # Calculate the covariance of Data1 and Data2\n",
    "    covar_d1_d2 = np.diagonal(ma.cov(ma.array(data1, mask=np.isnan(data1)), ma.array(data2, mask = np.isnan(data2)),ddof=1),offset=1) # covariance of data1 and data2 is off diagonal element, masked to ignore nans\n",
    "    \n",
    "    # Calculate the unscaled error variances for each dataset\n",
    "    # Covariance is symmetrical, so cov(d1,d2)==cov(d2,d1)\n",
    "    errorvar_d1 = (var_d1-((covar_d1_d2*covar_d1_d3)/covar_d2_d3))\n",
    "    errorvar_d2 = (var_d2-((covar_d1_d2*covar_d2_d3)/covar_d1_d3))\n",
    "    errorvar_d3 = (var_d3-((covar_d1_d3*covar_d2_d3)/covar_d1_d2))\n",
    "\n",
    "    # Determine rescaling parameters if desired\n",
    "    # Rescale to d1\n",
    "    #rescale_d2 = (covar_d1_d3/covar_d2_d3)\n",
    "    #rescale_d3 = (covar_d1_d2/covar_d2_d3)\n",
    "\n",
    "    #errorvar_d1 = errorvar_d1\n",
    "    #errorvar_d2 = errorvar_d2*(rescale_d2**2)\n",
    "    #errorvar_d3 = errorvar_d3*(rescale_d3**2)\n",
    "\n",
    "    # Calculate RMSD from the unscaled error variances\n",
    "    rmsd_d1 = np.sqrt(errorvar_d1);\n",
    "    rmsd_d2 = np.sqrt(errorvar_d2);\n",
    "    rmsd_d3 = np.sqrt(errorvar_d3);\n",
    "    \n",
    "    # It is possible to have negative unscaled variances which means imaginary rmsd. Only keep positive variances, real rmsd.\n",
    "    # Replace imaginary numbers with NaN\n",
    "    # NumPy sqrt only returns sqrts for positive values, replace masked, invalid numbers with NaN\n",
    "    rmsd_d1 = rmsd_d1.filled(np.nan)\n",
    "    rmsd_d2 = rmsd_d2.filled(np.nan)\n",
    "    rmsd_d3 = rmsd_d3.filled(np.nan)\n",
    "    \n",
    "    return [rmsd_d1,rmsd_d2,rmsd_d3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
